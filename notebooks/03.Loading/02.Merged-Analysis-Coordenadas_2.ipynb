{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las librerías necesarias\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns  \n",
    "from pathlib import Path\n",
    "import glob\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.decomposition import PCA  \n",
    "from sklearn.cluster import KMeans\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecer el random seed\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar y Explorar los Datos\n",
    "Carga el archivo parquet usando pandas y realiza una exploración inicial de los datos, incluyendo estadísticas descriptivas y visualización de distribuciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar todos los archivos parquet que contienen 'merged_inmuebles24_departamentos_duckdb'\n",
    "data_folder = '../../data/processed/'\n",
    "pattern = f\"{data_folder}*merged_inmuebles24_departamentos_duckdb*.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Buscar todos los archivos que coincidan con el patrón\n",
    "files = glob.glob(pattern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Archivos encontrados: {len(files)}\")\n",
    "for file in files:\n",
    "    print(f\"  - {Path(file).name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Leer y concatenar todos los archivos\n",
    "if len(files) == 0:\n",
    "    raise FileNotFoundError(f\"No se encontraron archivos con el patrón: {pattern}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfs = []\n",
    "for file in files:\n",
    "    temp_df = pd.read_parquet(file)\n",
    "    temp_df['source_file'] = Path(file).name  # Agregar columna con nombre del archivo fuente\n",
    "    dfs.append(temp_df)\n",
    "    print(f\"Cargado: {Path(file).name} - {len(temp_df)} registros\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar todos los DataFrames\n",
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar duplicados completos (todas las columnas)\n",
    "duplicados_completos = df.duplicated().sum()\n",
    "print(f\"\\n1. Duplicados completos (todas las columnas): {duplicados_completos}\")\n",
    "print(f\"   Porcentaje: {(duplicados_completos/len(df)*100):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar columnas clave para duplicados (excluyendo source_file)\n",
    "cols_clave = [col for col in df.columns if col != 'source_file']\n",
    "cols_clave\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicados por columnas clave\n",
    "duplicados_clave = df.duplicated(subset=cols_clave).sum()\n",
    "print(f\"\\n2. Duplicados por columnas clave (excluyendo source_file): {duplicados_clave}\")\n",
    "print(f\"   Porcentaje: {(duplicados_clave/len(df)*100):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si hay duplicados, mostrar ejemplos\n",
    "if duplicados_clave > 0:\n",
    "    print(\"\\n3. Ejemplos de registros duplicados:\")\n",
    "    mask_duplicados = df.duplicated(subset=cols_clave, keep=False)\n",
    "    ejemplos_duplicados = df[mask_duplicados].sort_values(by=cols_clave[:3]).head(10)\n",
    "    display(ejemplos_duplicados[['precio_mxn', 'lote_m2', 'direccion', 'source_file'][:min(5, len(ejemplos_duplicados.columns))]])\n",
    "    \n",
    "    # Contar duplicados por archivo fuente\n",
    "    print(\"\\n4. Distribución de duplicados por archivo fuente:\")\n",
    "    duplicados_por_archivo = df[mask_duplicados].groupby('source_file').size().sort_values(ascending=False)\n",
    "    print(duplicados_por_archivo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar duplicados si existen\n",
    "if duplicados_clave > 0:\n",
    "    print(f\"\\n5. Eliminando {duplicados_clave} duplicados...\")\n",
    "    df_original_len = len(df)\n",
    "    df = df.drop_duplicates(subset=cols_clave, keep='first')\n",
    "    print(f\"   Registros antes: {df_original_len}\")\n",
    "    print(f\"   Registros después: {len(df)}\")\n",
    "    print(f\"   Registros eliminados: {df_original_len - len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de Nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar nulos por columna\n",
    "nulos_por_columna = df.isnull().sum().sort_values(ascending=False)\n",
    "porcentaje_nulos = (nulos_por_columna / len(df) * 100).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame de resumen\n",
    "resumen_nulos = pd.DataFrame({\n",
    "    'Valores_Nulos': nulos_por_columna,\n",
    "    'Porcentaje': porcentaje_nulos,\n",
    "    'Tipo_Dato': df.dtypes\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar solo columnas con nulos\n",
    "resumen_nulos_con_datos = resumen_nulos[resumen_nulos['Valores_Nulos'] > 0]\n",
    "\n",
    "print(f\"\\n1. Resumen general:\")\n",
    "print(f\"   Total de columnas: {len(df.columns)}\")\n",
    "print(f\"   Columnas con nulos: {len(resumen_nulos_con_datos)}\")\n",
    "print(f\"   Columnas sin nulos: {len(df.columns) - len(resumen_nulos_con_datos)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploración inicial de los datos\n",
    "# Mostrar las primeras filas del DataFrame\n",
    "print(\"Primeras filas del DataFrame:\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(resumen_nulos_con_datos) > 0:\n",
    "    print(f\"\\n2. Top 20 columnas con más valores nulos:\")\n",
    "    display(resumen_nulos_con_datos.head(20))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.AGEB.isnull()].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['AGEB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['Título'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['latitud', 'longitud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sort_values(ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cols = ['direccion','colonia','cp','neighbourhood','Título','Enlace','colonia_std','municipio',\n",
    "            'ENTIDAD', 'NOM_ENT', 'MUN', 'NOM_MUN', 'LOC', 'NOM_LOC', 'AGEB', 'MZA',\n",
    "            'key', 'ENTIDAD_fm', 'MUN_fm', 'LOC_fm', 'AGEB_fm',\n",
    "            'MZA_fm', 'CVEVIAL', 'CVESEG', 'CVEFT', 'NOMVIAL', 'TIPOVIAL',\n",
    "            'CVEVIAL1', 'CVESEG1', 'CVEREF1', 'TIPOVR1', 'NOMREF1', 'CVEVIAL2',\n",
    "            'CVESEG2', 'CVEREF2', 'TIPOVR2', 'NOMREF2', 'CVEVIAL3', 'CVESEG3',\n",
    "            'CVEREF3', 'TIPOVR3', 'NOMREF3', 'municipio_1', 'address', 'road',\n",
    "            'quarter', 'borough', 'postcode', 'neighbourhood', 'source_file', \n",
    "            'lon', 'lat','latitud_1', 'longitud_1','distancia','latitud','longitud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['precio_mxn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = list(set(df.columns) - set(obj_cols) - set(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uppercase_columns = [col for col in df[numeric_cols].columns if col.isupper()]\n",
    "print(\"Columns with uppercase names:\", uppercase_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#porque sabemos de los datos del INEGI que no hay registros.\n",
    "df[uppercase_columns] = df[uppercase_columns].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lote_m2'] = df.groupby('colonia')['lote_m2'].transform(lambda x: x.fillna(int(x.mean())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['lote_m2'].isnull()].source_file.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información general del DataFrame\n",
    "print(\"\\nInformación general del DataFrame:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_int = list(df.select_dtypes('Int64').columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[fix_int] = df[fix_int].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas\n",
    "print(\"\\nEstadísticas descriptivas:\")\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de distribuciones\n",
    "# Seleccionar columnas numéricas\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Crear subplots para las columnas numéricas\n",
    "num_cols = len(numeric_columns)\n",
    "fig, axes = plt.subplots(nrows=(num_cols // 3) + 1, ncols=3, figsize=(15, 5 * ((num_cols // 3) + 1)))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, column in enumerate(numeric_columns):\n",
    "    sns.histplot(df[column], kde=True, bins=30, ax=axes[i])\n",
    "    axes[i].set_title(f\"Distribución de {column}\")\n",
    "    axes[i].set_xlabel(column)\n",
    "    axes[i].set_ylabel(\"Frecuencia\")\n",
    "\n",
    "# Eliminar ejes vacíos si hay menos subplots que espacios\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "municipio_order = df['municipio'].value_counts().index\n",
    "\n",
    "sns.countplot(data=df, x='municipio', order=municipio_order, hue='municipio')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Distribución de municipios')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.colonia.value_counts().head(10).plot(kind='bar', figsize=(12,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un CP puede contener varias colonias, así que nos quedamos sólo con colonias\n",
    "df.cp.value_counts().head(10).plot(kind='bar', figsize=(12,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_cols= list(df.colonia.value_counts().head(10).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['colonia_top10'] = df['colonia'].where(df['colonia'].isin(top10_cols), 'otros')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento de Datos\n",
    "Aplica técnicas de limpieza de datos, manejo de valores nulos y codificación de variables categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar valores nulos en el DataFrame\n",
    "print(\"\\nValores nulos por columna:\")\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers\n",
    "# Función para detectar outliers usando el método del rango intercuartílico (IQR) \n",
    "def detectar_outliers_iqr(data, columna):\n",
    "    Q1 = data[columna].quantile(0.25)\n",
    "    Q3 = data[columna].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    limite_inferior = Q1 - 1.5 * IQR\n",
    "    limite_superior = Q3 + 1.5 * IQR\n",
    "    outliers = data[(data[columna] < limite_inferior) | (data[columna] > limite_superior)]\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar la función a las columnas numéricas\n",
    "for col in numeric_cols:\n",
    "    outliers = detectar_outliers_iqr(df, col)\n",
    "    print(f\"\\nNúmero de outliers en {col}: {len(outliers)}\")\n",
    "    if len(outliers) > 0:\n",
    "        print(outliers[[col]].head())\n",
    "    # Visualizar outliers\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f\"Boxplot de {col}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "identificamos 2 outliers evidentes y muy seprados del resto de los datos en lote_m2, los cuales eliminamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('lote_m2', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar los índices de los dos outliers más grandes\n",
    "outliers = df.sort_values('lote_m2', ascending=False).head(2).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar los outliers del DataFrame\n",
    "df = df.drop(outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = list(df.select_dtypes(include=[\"object\", \"category\"]).columns)\n",
    "categorical_columns.remove('direccion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['municipio','colonia_top10'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "Realiza un análisis de clustering para agrupar los datos en diferentes segmentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = df[numeric_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_analysis['random'] = np.random.rand(len(df_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df_analysis.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "df_analysis[cols] = scaler.fit_transform(df_analysis[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Arreglar los nulos y quitar esta celda\n",
    "df_analysis = df_analysis.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis.dtypes[120:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo PCA sin especificar n_components\n",
    "pca = PCA()\n",
    "pca.fit(df_analysis)\n",
    "\n",
    "# Calcular la varianza acumulada\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "#Gráfica de la varianza acumulada\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='--')\n",
    "plt.title('Varianza acumulada por número de componentes')\n",
    "plt.xlabel('Número de componentes')\n",
    "plt.ylabel('Varianza acumulada')\n",
    "plt.axhline(y=0.95, color='r', linestyle='-')\n",
    "plt.axvline(x=np.argmax(cumulative_variance >= 0.95) + 1, color='g', linestyle='-')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Elegir el número de componentes que expliquen al menos el 95% de la varianza\n",
    "n_components = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "print(f\"Número óptimo de componentes: {n_components}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Varianza acumulada:\")\n",
    "print(cumulative_variance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar PCA con el número óptimo de componentes\n",
    "pca = PCA(n_components=n_components)\n",
    "pca_data = pca.fit_transform(df_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de cada componente (varianza explicada)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(\"Varianza explicada por cada componente:\")\n",
    "for i, var in enumerate(explained_variance):\n",
    "    print(f\"Componente {i+1}: {var:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfica de varianza explicada por cada componente\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(1, len(explained_variance) + 1), explained_variance, alpha=0.7, label='Varianza explicada')\n",
    "plt.step(range(1, len(cumulative_variance) + 1), cumulative_variance, where='mid', label='Varianza acumulada')\n",
    "plt.axhline(y=0.95, color='r', linestyle='--', label='95% de varianza')\n",
    "plt.xlabel('Número de componentes principales')\n",
    "plt.ylabel('Proporción de varianza explicada')\n",
    "plt.title('Varianza explicada por componentes principales')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contribución de las características originales a los primeros 22 componentes\n",
    "components = pd.DataFrame(pca.components_[:20], columns=df_analysis.columns)\n",
    "print(\"\\nContribución de las características originales a los primeros 22 componentes:\")\n",
    "components.T.sort_values(by = 0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_important_features = components.iloc[0].abs().sort_values(ascending=False).head(35)\n",
    "print(\"Características más importantes del primer componente:\")\n",
    "print(most_important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstrucción aproximada de los datos originales\n",
    "reconstructed_data = pca.inverse_transform(pca_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Comparar los datos originales con los reconstruidos\n",
    "print(\"Datos originales (primeras filas):\")\n",
    "df_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDatos reconstruidos (primeras filas):\")\n",
    "pd.DataFrame(reconstructed_data, columns=df_analysis.columns).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la inertia para diferentes números de clusters\n",
    "inertia = []\n",
    "for k in range(1, 21):  # Probar de 1 a 10 clusters\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(pca_data)  # Usa los datos reducidos por PCA\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Graficar el método del codo\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, 21), inertia, marker='o', linestyle='--')\n",
    "plt.xlabel('Número de clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Método del Codo')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Calcular el coeficiente de silueta para diferentes números de clusters\n",
    "silhouette_scores = []\n",
    "for k in range(2, 21):  # Probar de 2 a 10 clusters\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(pca_data)\n",
    "    score = silhouette_score(pca_data, kmeans.labels_)\n",
    "    silhouette_scores.append(score)\n",
    "\n",
    "# Graficar el coeficiente de silueta\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(2, 21), silhouette_scores, marker='o', linestyle='--')\n",
    "plt.xlabel('Número de clusters')\n",
    "plt.ylabel('Coeficiente de Silueta')\n",
    "plt.title('Coeficiente de Silueta para diferentes números de clusters')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar el algoritmo K-Means para clustering\n",
    "num_clusters = 10\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "clusters = kmeans.fit_predict(df_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Agregar los clusters al DataFrame original\n",
    "df_analysis['Cluster'] = clusters\n",
    "\n",
    "# Visualizar los clusters en el espacio reducido por PCA\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=pca_data[:, 0], y=pca_data[:, 1], hue=clusters, palette=\"viridis\", s=50)\n",
    "plt.title(\"Visualización de Clusters (K-Means)\")\n",
    "plt.xlabel(\"Componente Principal 1\")\n",
    "plt.ylabel(\"Componente Principal 2\")\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Crear un DataFrame con los datos de PCA y clusters\n",
    "df_pca = pd.DataFrame(pca_data[:,:3], columns=['PC1', 'PC2', 'PC3'])  # Asegúrate de que pca_data tenga al menos 3 componentes\n",
    "df_pca['Cluster'] = clusters  # Agregar los clusters al DataFrame\n",
    "\n",
    "# Graficar en 3D con plotly\n",
    "fig = px.scatter_3d(\n",
    "    df_pca,\n",
    "    x='PC1', y='PC2', z='PC3',  # Ejes del gráfico\n",
    "    color='Cluster',            # Colorear por cluster\n",
    "    title=\"Visualización de Clusters en 3D (K-Means)\",\n",
    "    opacity=0.3,                # Transparencia de los puntos\n",
    "    size_max=1,                 # Tamaño máximo de los puntos\n",
    "    symbol_sequence=['circle'], # Usar círculos como símbolo\n",
    "    color_continuous_scale='Viridis'  # Paleta de colores\n",
    ")\n",
    "\n",
    "# Ajustar el tamaño del gráfico\n",
    "fig.update_layout(\n",
    "    width=600,  # Ancho del gráfico\n",
    "    height=600   # Alto del gráfico\n",
    ")\n",
    "\n",
    "# Mostrar el gráfico interactivo\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar el tamaño de cada cluster\n",
    "cluster_sizes = df_analysis['Cluster'].value_counts()\n",
    "print(\"\\nTamaño de cada cluster:\")\n",
    "cluster_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular las características promedio de cada cluster\n",
    "numeric_columns = df_analysis.select_dtypes('number')\n",
    "cluster_means = numeric_columns.groupby(df_analysis['Cluster']).mean()\n",
    "cluster_means.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings = pd.DataFrame(\n",
    "            pca.components_.T,\n",
    "            columns=[f'PC{i+1}' for i in range(pca.n_components_)],\n",
    "            index=df_analysis.drop('Cluster',axis =1).columns\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_pca = np.sum(\n",
    "            loadings.abs() * pca.explained_variance_ratio_, axis=1\n",
    "        )\n",
    "feature_importance_pca = feature_importance_pca.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)  # Mostrar todas las filas\n",
    "feature_importance_pca.sort_values(ascending=False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_pca.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_position = feature_importance_pca.index.get_loc('random')\n",
    "# Quedarse solo con las features antes de 'random'\n",
    "#filtered_features = feature_importance_pca.iloc[:random_position]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_features.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_features = list(filtered_features.index)\n",
    "final_features = list(feature_importance_pca.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la matriz de correlación para las características seleccionadas\n",
    "correlation_matrix = df[final_features].corr()\n",
    "\n",
    "# Visualizar la matriz de correlación\n",
    "plt.figure(figsize=(36, 30))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True)\n",
    "plt.title(\"Matriz de Correlación de las Características Seleccionadas\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecer un umbral para considerar alta correlación\n",
    "correlation_threshold = 0.60\n",
    "\n",
    "# Identificar pares de características altamente correlacionadas\n",
    "high_corr_pairs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > correlation_threshold:\n",
    "            high_corr_pairs.append((correlation_matrix.columns[i], correlation_matrix.columns[j]))\n",
    "\n",
    "print(f\"Pares de características altamente correlacionadas (umbral > {correlation_threshold}):\")\n",
    "high_corr_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un conjunto para almacenar las características a eliminar\n",
    "features_to_remove = set()\n",
    "\n",
    "# Para cada par de características correlacionadas, eliminar la menos importante según PCA\n",
    "for feature1, feature2 in high_corr_pairs:\n",
    "    if feature_importance_pca[feature1] < feature_importance_pca[feature2]:\n",
    "        features_to_remove.add(feature1)\n",
    "    else:\n",
    "        features_to_remove.add(feature2)\n",
    "\n",
    "# Filtrar las características finales eliminando las correlacionadas menos importantes\n",
    "final_features_filtered = [feature for feature in final_features if feature not in features_to_remove]\n",
    "\n",
    "print(f\"Características finales después de eliminar correlacionadas: {len(final_features_filtered)}\")\n",
    "final_features_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = final_features_filtered.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresión Lineal con Pipeline Completo\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Seleccionar las características (X) y la variable objetivo (y)\n",
    "target_column = 'precio_mxn'\n",
    "\n",
    "# Filtrar features antes de 'random' si existe\n",
    "if 'random' in final_features:\n",
    "    final_features_filtered = final_features[:final_features.index('random')]\n",
    "    print(f\"Filtradas {len(final_features_filtered)} features antes de 'random'\")\n",
    "else:\n",
    "    final_features_filtered = final_features\n",
    "    print(f\"Usando todas las {len(final_features_filtered)} features\")\n",
    "\n",
    "X = df[final_features_filtered]\n",
    "y = df[target_column]\n",
    "\n",
    "print(f\"Forma del dataset: X {X.shape}, y {y.shape}\")\n",
    "print(f\"Features seleccionadas: {final_features_filtered}\")\n",
    "\n",
    "# Verificar valores faltantes\n",
    "print(f\"\\nValores faltantes en X: {X.isnull().sum().sum()}\")\n",
    "print(f\"Valores faltantes en y: {y.isnull().sum()}\")\n",
    "\n",
    "# Eliminar filas con valores faltantes si los hay\n",
    "if X.isnull().sum().sum() > 0 or y.isnull().sum() > 0:\n",
    "    mask = ~(X.isnull().any(axis=1) | y.isnull())\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "    print(f\"Después de eliminar NaN: X {X.shape}, y {y.shape}\")\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=None  # Para regresión no usamos stratify\n",
    ")\n",
    "\n",
    "print(f\"\\nDivisión de datos:\")\n",
    "print(f\"Entrenamiento: X {X_train.shape}, y {y_train.shape}\")\n",
    "print(f\"Prueba: X {X_test.shape}, y {y_test.shape}\")\n",
    "\n",
    "# Crear el pipeline con StandardScaler y LinearRegression\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Entrenar el modelo\n",
    "print(\"\\nEntrenando el modelo...\")\n",
    "start_time = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "training_time = end_time - start_time \n",
    "print(f\"Entrenamiento completado en {training_time:.2f} segundos.\")\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_train = pipeline.predict(X_train)\n",
    "y_pred_test = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "def evaluate_model(y_true, y_pred, dataset_name=\"\"):\n",
    "    \"\"\"Función para evaluar el modelo con múltiples métricas\"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\nResultados {dataset_name}:\")\n",
    "    print(f\"Error cuadrático medio (MSE): {mse:,.2f}\")\n",
    "    print(f\"Raíz del error cuadrático medio (RMSE): {rmse:,.2f}\")\n",
    "    print(f\"Error absoluto medio (MAE): {mae:,.2f}\")\n",
    "    print(f\"Coeficiente de determinación (R²): {r2:.4f}\")\n",
    "    \n",
    "    return {'mse': mse, 'rmse': rmse, 'mae': mae, 'r2': r2}\n",
    "\n",
    "# Evaluar en entrenamiento y prueba\n",
    "train_metrics = evaluate_model(y_train, y_pred_train, \"Entrenamiento\")\n",
    "test_metrics = evaluate_model(y_test, y_pred_test, \"Prueba\")\n",
    "\n",
    "# Validación cruzada\n",
    "print(f\"\\nValidación cruzada (5-fold):\")\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='r2')\n",
    "print(f\"R² promedio: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "cv_scores_rmse = cross_val_score(pipeline, X_train, y_train, cv=5, \n",
    "                                scoring='neg_mean_squared_error')\n",
    "cv_rmse = np.sqrt(-cv_scores_rmse)\n",
    "print(f\"RMSE promedio: {cv_rmse.mean():,.2f} (+/- {cv_rmse.std() * 2:,.2f})\")\n",
    "\n",
    "# Análisis de coeficientes\n",
    "scaler = pipeline.named_steps['scaler']\n",
    "regressor = pipeline.named_steps['regressor']\n",
    "\n",
    "# Obtener coeficientes e importancia\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': final_features_filtered,\n",
    "    'coefficient': regressor.coef_,\n",
    "    'abs_coefficient': np.abs(regressor.coef_)\n",
    "}).sort_values('abs_coefficient', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 10 características más importantes:\")\n",
    "print(feature_importance.head(10).to_string(index=False))\n",
    "\n",
    "# Visualizaciones mejoradas\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Predicciones vs Valores Reales (Prueba)\n",
    "axes[0,0].scatter(y_test, y_pred_test, alpha=0.6, color='blue', s=30)\n",
    "axes[0,0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "               color='red', linestyle='--', linewidth=2)\n",
    "axes[0,0].set_title(f\"Predicciones vs Valores Reales (Prueba)\\nR² = {test_metrics['r2']:.4f}\")\n",
    "axes[0,0].set_xlabel(\"Valores Reales\")\n",
    "axes[0,0].set_ylabel(\"Predicciones\")\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Residuos vs Predicciones\n",
    "residuals_test = y_test - y_pred_test\n",
    "axes[0,1].scatter(y_pred_test, residuals_test, alpha=0.6, color='green', s=30)\n",
    "axes[0,1].axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[0,1].set_title(\"Residuos vs Predicciones\")\n",
    "axes[0,1].set_xlabel(\"Predicciones\")\n",
    "axes[0,1].set_ylabel(\"Residuos\")\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Distribución de residuos\n",
    "axes[1,0].hist(residuals_test, bins=30, alpha=0.7, color='purple', edgecolor='black')\n",
    "axes[1,0].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1,0].set_title(\"Distribución de Residuos\")\n",
    "axes[1,0].set_xlabel(\"Residuos\")\n",
    "axes[1,0].set_ylabel(\"Frecuencia\")\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Importancia de características (Top 10)\n",
    "top_10_features = feature_importance.head(10)\n",
    "axes[1,1].barh(range(len(top_10_features)), top_10_features['abs_coefficient'])\n",
    "axes[1,1].set_yticks(range(len(top_10_features)))\n",
    "axes[1,1].set_yticklabels(top_10_features['feature'])\n",
    "axes[1,1].set_title(\"Top 10 Características Más Importantes\")\n",
    "axes[1,1].set_xlabel(\"Valor Absoluto del Coeficiente\")\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Comparación Entrenamiento vs Prueba\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Métrica': ['MSE', 'RMSE', 'MAE', 'R²'],\n",
    "    'Entrenamiento': [train_metrics['mse'], train_metrics['rmse'], \n",
    "                     train_metrics['mae'], train_metrics['r2']],\n",
    "    'Prueba': [test_metrics['mse'], test_metrics['rmse'], \n",
    "              test_metrics['mae'], test_metrics['r2']]\n",
    "})\n",
    "\n",
    "print(f\"\\nComparación Entrenamiento vs Prueba:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Detectar posible overfitting\n",
    "if train_metrics['r2'] - test_metrics['r2'] > 0.1:\n",
    "    print(f\"\\n⚠️  Posible overfitting detectado:\")\n",
    "    print(f\"   Diferencia R²: {train_metrics['r2'] - test_metrics['r2']:.4f}\")\n",
    "elif test_metrics['r2'] < 0.5:\n",
    "    print(f\"\\n⚠️  Modelo con bajo rendimiento:\")\n",
    "    print(f\"   R² en prueba: {test_metrics['r2']:.4f}\")\n",
    "else:\n",
    "    print(f\"\\n✅ Modelo con buen rendimiento y generalización\")\n",
    "\n",
    "# Guardar el modelo entrenado y métricas\n",
    "model_results_linear = {\n",
    "    'pipeline': pipeline,\n",
    "    'train_metrics': train_metrics,\n",
    "    'test_metrics': test_metrics,\n",
    "    'feature_importance': feature_importance,\n",
    "    'cv_scores': cv_scores,\n",
    "    'training_time': training_time\n",
    "}\n",
    "\n",
    "print(f\"\\nModelo entrenado exitosamente con {len(final_features_filtered)} características\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresión No Lineal con Pipeline (Random Forest Regressor)\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "# Importamos el nuevo modelo: Random Forest Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Asunciones de variables (DEBEN estar definidas en el entorno global) ---\n",
    "# df, final_features, y target_column deben estar disponibles antes de la ejecución\n",
    "# Ejemplo de variables si no estuvieran definidas:\n",
    "# data_size = 500\n",
    "# final_features = [f'feature_{i}' for i in range(5)]\n",
    "# df = pd.DataFrame(np.random.rand(data_size, 5), columns=final_features)\n",
    "# df['precio_mxn'] = df.iloc[:, 0] * 100 + df.iloc[:, 1] * 50 + np.random.randn(data_size) * 10\n",
    "# target_column = 'precio_mxn'\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "# Seleccionar las características (X) y la variable objetivo (y)\n",
    "# Suponiendo que df, final_features y target_column ya están cargados/definidos\n",
    "# Aquí usaremos un pequeño ejemplo para que el código sea runnable de forma autónoma:\n",
    "try:\n",
    "    X = df[final_features_filtered]\n",
    "    y = df[target_column]\n",
    "except NameError:\n",
    "    print(\"⚠️ Usando datos de ejemplo ya que 'df' no está definido en el entorno.\")\n",
    "    data_size = 1000\n",
    "    final_features = [f'area_m2', 'num_habitaciones', 'distancia_centro_km', 'antiguedad_anos', 'dummy_col']\n",
    "    df = pd.DataFrame(np.random.rand(data_size, 5), columns=final_features)\n",
    "    df['precio_mxn'] = (df['area_m2'] * 500000) + (df['num_habitaciones'] * 100000) + (np.random.randn(data_size) * 50000)\n",
    "    target_column = 'precio_mxn'\n",
    "    final_features_filtered = final_features\n",
    "    X = df[final_features_filtered]\n",
    "    y = df[target_column]\n",
    "\n",
    "\n",
    "print(f\"Forma del dataset: X {X.shape}, y {y.shape}\")\n",
    "print(f\"Features seleccionadas: {final_features_filtered}\")\n",
    "\n",
    "# Verificar y limpiar valores faltantes (mismo código que el original)\n",
    "if X.isnull().sum().sum() > 0 or y.isnull().sum() > 0:\n",
    "    mask = ~(X.isnull().any(axis=1) | y.isnull())\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "    print(f\"Después de eliminar NaN: X {X.shape}, y {y.shape}\")\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nDivisión de datos:\")\n",
    "print(f\"Entrenamiento: X {X_train.shape}, y {y_train.shape}\")\n",
    "print(f\"Prueba: X {X_test.shape}, y {y_test.shape}\")\n",
    "\n",
    "# --- CAMBIO CLAVE: Reemplazar LinearRegression por RandomForestRegressor ---\n",
    "# Random Forest es un modelo de ensamble basado en árboles que captura no linealidades.\n",
    "# El StandardScaler (escalamiento) es menos crítico aquí, pero se mantiene en el pipeline.\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', RandomForestRegressor(\n",
    "        n_estimators=100,  # Número de árboles en el bosque\n",
    "        max_depth=10,      # Profundidad máxima de los árboles para evitar sobreajuste\n",
    "        random_state=42,\n",
    "        n_jobs=-1          # Usa todos los núcleos de CPU disponibles\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Entrenar el modelo\n",
    "print(\"\\nEntrenando el modelo Random Forest...\")\n",
    "start_time = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "training_time = end_time - start_time\n",
    "print(f\"Entrenamiento completado en {training_time:.2f} segundos.\")\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_train = pipeline.predict(X_train)\n",
    "y_pred_test = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo (función de evaluación reutilizada)\n",
    "def evaluate_model(y_true, y_pred, dataset_name=\"\"):\n",
    "    \"\"\"Función para evaluar el modelo con múltiples métricas\"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\nResultados {dataset_name}:\")\n",
    "    print(f\"Error cuadrático medio (MSE): {mse:,.2f}\")\n",
    "    print(f\"Raíz del error cuadrático medio (RMSE): {rmse:,.2f}\")\n",
    "    print(f\"Error absoluto medio (MAE): {mae:,.2f}\")\n",
    "    print(f\"Coeficiente de determinación (R²): {r2:.4f}\")\n",
    "    \n",
    "    return {'mse': mse, 'rmse': rmse, 'mae': mae, 'r2': r2}\n",
    "\n",
    "# Evaluar en entrenamiento y prueba\n",
    "train_metrics = evaluate_model(y_train, y_pred_train, \"Entrenamiento (Random Forest)\")\n",
    "test_metrics = evaluate_model(y_test, y_pred_test, \"Prueba (Random Forest)\")\n",
    "\n",
    "# Validación cruzada\n",
    "print(f\"\\nValidación cruzada (5-fold):\")\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='r2', n_jobs=-1)\n",
    "print(f\"R² promedio: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "cv_scores_rmse = cross_val_score(pipeline, X_train, y_train, cv=5, \n",
    "                                scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "cv_rmse = np.sqrt(-cv_scores_rmse)\n",
    "print(f\"RMSE promedio: {cv_rmse.mean():,.2f} (+/- {cv_rmse.std() * 2:,.2f})\")\n",
    "\n",
    "# Análisis de Importancia de Características (diferente al de Regresión Lineal)\n",
    "regressor = pipeline.named_steps['regressor']\n",
    "\n",
    "# Obtener la importancia de las características del Random Forest\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': final_features_filtered,\n",
    "    'importance': regressor.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 10 características más importantes (Random Forest):\")\n",
    "# Usamos 'importance' en lugar de 'abs_coefficient'\n",
    "print(feature_importance.head(10).to_string(index=False))\n",
    "\n",
    "# Visualizaciones mejoradas (reutilizando la estructura de la gráfica)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Predicciones vs Valores Reales (Prueba)\n",
    "axes[0,0].scatter(y_test, y_pred_test, alpha=0.6, color='#FF5733', s=30)\n",
    "axes[0,0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "               color='#33FF57', linestyle='--', linewidth=2)\n",
    "axes[0,0].set_title(f\"Predicciones vs Valores Reales (Prueba)\\nR² = {test_metrics['r2']:.4f}\", \n",
    "                    fontsize=14, color='#333333')\n",
    "axes[0,0].set_xlabel(\"Valores Reales (precio_mxn)\", fontsize=12)\n",
    "axes[0,0].set_ylabel(\"Predicciones (precio_mxn)\", fontsize=12)\n",
    "axes[0,0].grid(True, alpha=0.3, linestyle=':')\n",
    "\n",
    "# 2. Residuos vs Predicciones\n",
    "residuals_test = y_test - y_pred_test\n",
    "axes[0,1].scatter(y_pred_test, residuals_test, alpha=0.6, color='#33AFFF', s=30)\n",
    "axes[0,1].axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[0,1].set_title(\"Residuos vs Predicciones (Idealmente aleatorio)\", \n",
    "                    fontsize=14, color='#333333')\n",
    "axes[0,1].set_xlabel(\"Predicciones\", fontsize=12)\n",
    "axes[0,1].set_ylabel(\"Residuos (Error)\", fontsize=12)\n",
    "axes[0,1].grid(True, alpha=0.3, linestyle=':')\n",
    "\n",
    "# 3. Distribución de residuos\n",
    "axes[1,0].hist(residuals_test, bins=30, alpha=0.8, color='#AFFF33', edgecolor='black')\n",
    "axes[1,0].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1,0].set_title(\"Distribución de Residuos (Idealmente normal y centrado en 0)\", \n",
    "                    fontsize=14, color='#333333')\n",
    "axes[1,0].set_xlabel(\"Residuos\", fontsize=12)\n",
    "axes[1,0].set_ylabel(\"Frecuencia\", fontsize=12)\n",
    "axes[1,0].grid(True, alpha=0.3, linestyle=':')\n",
    "\n",
    "# 4. Importancia de características (Top 10)\n",
    "top_10_features = feature_importance.head(10)\n",
    "axes[1,1].barh(range(len(top_10_features)), top_10_features['importance'], color='#9A33FF')\n",
    "axes[1,1].set_yticks(range(len(top_10_features)))\n",
    "axes[1,1].set_yticklabels(top_10_features['feature'], fontsize=10)\n",
    "axes[1,1].set_title(\"Top 10 Características Más Importantes (Random Forest)\", \n",
    "                    fontsize=14, color='#333333')\n",
    "axes[1,1].set_xlabel(\"Importancia (Gini Impurity)\", fontsize=12)\n",
    "axes[1,1].invert_yaxis() # Pone la más importante arriba\n",
    "axes[1,1].grid(axis='x', alpha=0.3, linestyle=':')\n",
    "\n",
    "plt.suptitle(\"Evaluación del Modelo Random Forest Regressor\", fontsize=16, fontweight='bold')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
    "plt.show()\n",
    "\n",
    "# Comparación Entrenamiento vs Prueba\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Métrica': ['MSE', 'RMSE', 'MAE', 'R²'],\n",
    "    'Entrenamiento': [train_metrics['mse'], train_metrics['rmse'], \n",
    "                     train_metrics['mae'], train_metrics['r2']],\n",
    "    'Prueba': [test_metrics['mse'], test_metrics['rmse'], \n",
    "              test_metrics['mae'], test_metrics['r2']]\n",
    "})\n",
    "\n",
    "print(f\"\\nComparación Entrenamiento vs Prueba:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Detectar posible overfitting\n",
    "# En Random Forest, la diferencia R² tiende a ser mayor, pero el R² de prueba debe ser alto.\n",
    "r2_diff = train_metrics['r2'] - test_metrics['r2']\n",
    "if r2_diff > 0.15: # Un umbral más alto para modelos de árbol\n",
    "    print(f\"\\n⚠️  Random Forest detectado con posible sobreajuste (Overfitting):\")\n",
    "    print(f\"   Diferencia R² (Entrenamiento - Prueba): {r2_diff:.4f}\")\n",
    "    print(\"   Considera reducir max_depth o aumentar min_samples_split.\")\n",
    "elif test_metrics['r2'] < 0.6:\n",
    "    print(f\"\\n⚠️  Modelo con bajo rendimiento:\")\n",
    "    print(f\"   R² en prueba: {test_metrics['r2']:.4f}\")\n",
    "else:\n",
    "    print(f\"\\n✅ Modelo Random Forest con buen rendimiento y generalización.\")\n",
    "\n",
    "# Guardar el modelo entrenado y métricas (actualizado)\n",
    "model_results_rf = {\n",
    "    'pipeline': pipeline,\n",
    "    'train_metrics': train_metrics,\n",
    "    'test_metrics': test_metrics,\n",
    "    'feature_importance': feature_importance,\n",
    "    'cv_scores': cv_scores,\n",
    "    'training_time': training_time\n",
    "}\n",
    "\n",
    "print(f\"\\nModelo Random Forest entrenado exitosamente con {len(final_features_filtered)} características\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresión No Lineal con Pipeline (Gradient Boosting Regressor)\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "# Importamos el nuevo modelo: Gradient Boosting Regressor (GBM)\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Asunciones de variables (DEBEN estar definidas en el entorno global) ---\n",
    "# df, final_features, y target_column deben estar disponibles antes de la ejecución\n",
    "# Ejemplo de variables si no estuvieran definidas:\n",
    "# data_size = 500\n",
    "# final_features = [f'feature_{i}' for i in range(5)]\n",
    "# df = pd.DataFrame(np.random.rand(data_size, 5), columns=final_features)\n",
    "# df['precio_mxn'] = df.iloc[:, 0] * 100 + df.iloc[:, 1] * 50 + np.random.randn(data_size) * 10\n",
    "# target_column = 'precio_mxn'\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "# Seleccionar las características (X) y la variable objetivo (y)\n",
    "# Suponiendo que df, final_features y target_column ya están cargados/definidos\n",
    "# Aquí usaremos un pequeño ejemplo para que el código sea runnable de forma autónoma:\n",
    "try:\n",
    "    X = df[final_features_filtered]\n",
    "    y = df[target_column]\n",
    "except NameError:\n",
    "    print(\"⚠️ Usando datos de ejemplo ya que 'df' no está definido en el entorno.\")\n",
    "    data_size = 1000\n",
    "    final_features = [f'area_m2', 'num_habitaciones', 'distancia_centro_km', 'antiguedad_anos', 'dummy_col']\n",
    "    df = pd.DataFrame(np.random.rand(data_size, 5), columns=final_features)\n",
    "    df['precio_mxn'] = (df['area_m2'] * 500000) + (df['num_habitaciones'] * 100000) + (np.random.randn(data_size) * 50000)\n",
    "    target_column = 'precio_mxn'\n",
    "    final_features_filtered = final_features\n",
    "    X = df[final_features_filtered]\n",
    "    y = df[target_column]\n",
    "\n",
    "\n",
    "print(f\"Forma del dataset: X {X.shape}, y {y.shape}\")\n",
    "print(f\"Features seleccionadas: {final_features_filtered}\")\n",
    "\n",
    "# Verificar y limpiar valores faltantes (mismo código que el original)\n",
    "if X.isnull().sum().sum() > 0 or y.isnull().sum() > 0:\n",
    "    mask = ~(X.isnull().any(axis=1) | y.isnull())\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "    print(f\"Después de eliminar NaN: X {X.shape}, y {y.shape}\")\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nDivisión de datos:\")\n",
    "print(f\"Entrenamiento: X {X_train.shape}, y {y_train.shape}\")\n",
    "print(f\"Prueba: X {X_test.shape}, y {y_test.shape}\")\n",
    "\n",
    "# --- CAMBIO CLAVE: Reemplazar RandomForestRegressor por GradientBoostingRegressor (GBM) ---\n",
    "# GBM es un modelo de ensamble basado en boosting (aprendizaje secuencial) que a menudo \n",
    "# ofrece un mejor rendimiento que Random Forest.\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', GradientBoostingRegressor(\n",
    "        n_estimators=100,      # Número de etapas de boosting (árboles)\n",
    "        learning_rate=0.1,     # Tasa de aprendizaje, controla la contribución de cada árbol\n",
    "        max_depth=3,           # Profundidad máxima de cada árbol (se prefieren árboles poco profundos)\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Entrenar el modelo\n",
    "print(\"\\nEntrenando el modelo Gradient Boosting Regressor (GBM)...\")\n",
    "start_time = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "training_time = end_time - start_time\n",
    "print(f\"Entrenamiento completado en {training_time:.2f} segundos.\")\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_train = pipeline.predict(X_train)\n",
    "y_pred_test = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo (función de evaluación reutilizada)\n",
    "def evaluate_model(y_true, y_pred, dataset_name=\"\"):\n",
    "    \"\"\"Función para evaluar el modelo con múltiples métricas\"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\nResultados {dataset_name}:\")\n",
    "    print(f\"Error cuadrático medio (MSE): {mse:,.2f}\")\n",
    "    print(f\"Raíz del error cuadrático medio (RMSE): {rmse:,.2f}\")\n",
    "    print(f\"Error absoluto medio (MAE): {mae:,.2f}\")\n",
    "    print(f\"Coeficiente de determinación (R²): {r2:.4f}\")\n",
    "    \n",
    "    return {'mse': mse, 'rmse': rmse, 'mae': mae, 'r2': r2}\n",
    "\n",
    "# Evaluar en entrenamiento y prueba\n",
    "train_metrics = evaluate_model(y_train, y_pred_train, \"Entrenamiento (GBM)\")\n",
    "test_metrics = evaluate_model(y_test, y_pred_test, \"Prueba (GBM)\")\n",
    "\n",
    "# Validación cruzada\n",
    "print(f\"\\nValidación cruzada (5-fold):\")\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='r2', n_jobs=-1)\n",
    "print(f\"R² promedio: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "cv_scores_rmse = cross_val_score(pipeline, X_train, y_train, cv=5, \n",
    "                                scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "cv_rmse = np.sqrt(-cv_scores_rmse)\n",
    "print(f\"RMSE promedio: {cv_rmse.mean():,.2f} (+/- {cv_rmse.std() * 2:,.2f})\")\n",
    "\n",
    "# Análisis de Importancia de Características (misma forma que Random Forest)\n",
    "regressor = pipeline.named_steps['regressor']\n",
    "\n",
    "# Obtener la importancia de las características del Gradient Boosting\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': final_features_filtered,\n",
    "    'importance': regressor.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 10 características más importantes (Gradient Boosting):\")\n",
    "print(feature_importance.head(10).to_string(index=False))\n",
    "\n",
    "# Visualizaciones mejoradas (reutilizando la estructura de la gráfica)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Predicciones vs Valores Reales (Prueba)\n",
    "axes[0,0].scatter(y_test, y_pred_test, alpha=0.6, color='#FF5733', s=30)\n",
    "axes[0,0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "               color='#33FF57', linestyle='--', linewidth=2)\n",
    "axes[0,0].set_title(f\"Predicciones vs Valores Reales (Prueba - GBM)\\nR² = {test_metrics['r2']:.4f}\", \n",
    "                    fontsize=14, color='#333333')\n",
    "axes[0,0].set_xlabel(\"Valores Reales (precio_mxn)\", fontsize=12)\n",
    "axes[0,0].set_ylabel(\"Predicciones (precio_mxn)\", fontsize=12)\n",
    "axes[0,0].grid(True, alpha=0.3, linestyle=':')\n",
    "\n",
    "# 2. Residuos vs Predicciones\n",
    "residuals_test = y_test - y_pred_test\n",
    "axes[0,1].scatter(y_pred_test, residuals_test, alpha=0.6, color='#33AFFF', s=30)\n",
    "axes[0,1].axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[0,1].set_title(\"Residuos vs Predicciones (GBM)\", \n",
    "                    fontsize=14, color='#333333')\n",
    "axes[0,1].set_xlabel(\"Predicciones\", fontsize=12)\n",
    "axes[0,1].set_ylabel(\"Residuos (Error)\", fontsize=12)\n",
    "axes[0,1].grid(True, alpha=0.3, linestyle=':')\n",
    "\n",
    "# 3. Distribución de residuos\n",
    "axes[1,0].hist(residuals_test, bins=30, alpha=0.8, color='#AFFF33', edgecolor='black')\n",
    "axes[1,0].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1,0].set_title(\"Distribución de Residuos (GBM)\", \n",
    "                    fontsize=14, color='#333333')\n",
    "axes[1,0].set_xlabel(\"Residuos\", fontsize=12)\n",
    "axes[1,0].set_ylabel(\"Frecuencia\", fontsize=12)\n",
    "axes[1,0].grid(True, alpha=0.3, linestyle=':')\n",
    "\n",
    "# 4. Importancia de características (Top 10)\n",
    "top_10_features = feature_importance.head(10)\n",
    "axes[1,1].barh(range(len(top_10_features)), top_10_features['importance'], color='#9A33FF')\n",
    "axes[1,1].set_yticks(range(len(top_10_features)))\n",
    "axes[1,1].set_yticklabels(top_10_features['feature'], fontsize=10)\n",
    "axes[1,1].set_title(\"Top 10 Características Más Importantes (GBM)\", \n",
    "                    fontsize=14, color='#333333')\n",
    "axes[1,1].set_xlabel(\"Importancia\", fontsize=12)\n",
    "axes[1,1].invert_yaxis() # Pone la más importante arriba\n",
    "axes[1,1].grid(axis='x', alpha=0.3, linestyle=':')\n",
    "\n",
    "plt.suptitle(\"Evaluación del Modelo Gradient Boosting Regressor (GBM)\", fontsize=16, fontweight='bold')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
    "plt.show()\n",
    "\n",
    "# Comparación Entrenamiento vs Prueba\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Métrica': ['MSE', 'RMSE', 'MAE', 'R²'],\n",
    "    'Entrenamiento': [train_metrics['mse'], train_metrics['rmse'], \n",
    "                     train_metrics['mae'], train_metrics['r2']],\n",
    "    'Prueba': [test_metrics['mse'], test_metrics['rmse'], \n",
    "              test_metrics['mae'], test_metrics['r2']]\n",
    "})\n",
    "\n",
    "print(f\"\\nComparación Entrenamiento vs Prueba:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Detectar posible overfitting\n",
    "# GBM es más propenso al sobreajuste que Random Forest, por lo que el umbral es más estricto.\n",
    "r2_diff = train_metrics['r2'] - test_metrics['r2']\n",
    "if r2_diff > 0.08: # Bajamos el umbral para modelos de boosting (0.08 es más estricto)\n",
    "    print(f\"\\n⚠️  Gradient Boosting detectado con posible sobreajuste (Overfitting):\")\n",
    "    print(f\"   Diferencia R² (Entrenamiento - Prueba): {r2_diff:.4f}\")\n",
    "    print(\"   Considera reducir el 'learning_rate', aumentar 'n_estimators' o usar 'subsample'.\")\n",
    "elif test_metrics['r2'] < 0.7:\n",
    "    print(f\"\\n⚠️  Modelo con bajo rendimiento:\")\n",
    "    print(f\"   R² en prueba: {test_metrics['r2']:.4f}\")\n",
    "else:\n",
    "    print(f\"\\n✅ Modelo Gradient Boosting con buen rendimiento y generalización.\")\n",
    "\n",
    "# Guardar el modelo entrenado y métricas (actualizado)\n",
    "model_results_gbm = {\n",
    "    'pipeline': pipeline,\n",
    "    'train_metrics': train_metrics,\n",
    "    'test_metrics': test_metrics,\n",
    "    'feature_importance': feature_importance,\n",
    "    'cv_scores': cv_scores,\n",
    "    'training_time': training_time\n",
    "}\n",
    "\n",
    "print(f\"\\nModelo Gradient Boosting entrenado exitosamente con {len(final_features_filtered)} características\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresión No Lineal Avanzada con Pipeline (XGBoost Regressor)\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Importamos el modelo de la librería externa: XGBoost Regressor ---\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "except ImportError:\n",
    "    # Mensaje de error si la librería XGBoost no está instalada (solo para entorno real)\n",
    "    print(\"Error: La librería 'xgboost' no está instalada. Por favor, instálela con 'pip install xgboost'\")\n",
    "    raise\n",
    "\n",
    "# --- Asunciones de variables (DEBEN estar definidas en el entorno global) ---\n",
    "# df, final_features, y target_column deben estar disponibles antes de la ejecución\n",
    "# Aquí usamos un pequeño ejemplo para que el código sea runnable de forma autónoma:\n",
    "try:\n",
    "    X = df[final_features_filtered]\n",
    "    y = df[target_column]\n",
    "except NameError:\n",
    "    print(\"⚠️ Usando datos de ejemplo ya que 'df' no está definido en el entorno.\")\n",
    "    data_size = 1000\n",
    "    final_features = [f'area_m2', 'num_habitaciones', 'distancia_centro_km', 'antiguedad_anos', 'dummy_col']\n",
    "    df = pd.DataFrame(np.random.rand(data_size, 5), columns=final_features)\n",
    "    df['precio_mxn'] = (df['area_m2'] * 500000) + (df['num_habitaciones'] * 100000) + (np.random.randn(data_size) * 50000)\n",
    "    target_column = 'precio_mxn'\n",
    "    final_features_filtered = final_features\n",
    "    X = df[final_features_filtered]\n",
    "    y = df[target_column]\n",
    "\n",
    "\n",
    "print(f\"Forma del dataset: X {X.shape}, y {y.shape}\")\n",
    "print(f\"Features seleccionadas: {final_features_filtered}\")\n",
    "\n",
    "# Verificar y limpiar valores faltantes (mismo código que el original)\n",
    "if X.isnull().sum().sum() > 0 or y.isnull().sum() > 0:\n",
    "    mask = ~(X.isnull().any(axis=1) | y.isnull())\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "    print(f\"Después de eliminar NaN: X {X.shape}, y {y.shape}\")\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nDivisión de datos:\")\n",
    "print(f\"Entrenamiento: X {X_train.shape}, y {y_train.shape}\")\n",
    "print(f\"Prueba: X {X_test.shape}, y {y_test.shape}\")\n",
    "\n",
    "# --- CAMBIO CLAVE: Reemplazar GradientBoostingRegressor por XGBRegressor ---\n",
    "# XGBoost es el modelo de Boosting optimizado y regularizado.\n",
    "pipeline = Pipeline([\n",
    "    # XGBoost no requiere escalado, pero lo mantenemos para consistencia\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('regressor', XGBRegressor(\n",
    "        n_estimators=100,      # Número de árboles (iters)\n",
    "        learning_rate=0.1,     # Tasa de aprendizaje\n",
    "        max_depth=5,           # Profundidad máxima (un poco más profunda que GBM)\n",
    "        random_state=42,\n",
    "        n_jobs=-1,             # Utiliza todos los núcleos de la CPU para rapidez\n",
    "        # Parámetros de regularización por defecto (l1 y l2)\n",
    "        objective='reg:squarederror' # Objetivo para regresión\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Entrenar el modelo\n",
    "print(\"\\nEntrenando el modelo XGBoost Regressor...\")\n",
    "start_time = time.time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "training_time = end_time - start_time\n",
    "print(f\"Entrenamiento completado en {training_time:.2f} segundos.\")\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_train = pipeline.predict(X_train)\n",
    "y_pred_test = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo (función de evaluación reutilizada)\n",
    "def evaluate_model(y_true, y_pred, dataset_name=\"\"):\n",
    "    \"\"\"Función para evaluar el modelo con múltiples métricas\"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\nResultados {dataset_name}:\")\n",
    "    print(f\"Error cuadrático medio (MSE): {mse:,.2f}\")\n",
    "    print(f\"Raíz del error cuadrático medio (RMSE): {rmse:,.2f}\")\n",
    "    print(f\"Error absoluto medio (MAE): {mae:,.2f}\")\n",
    "    print(f\"Coeficiente de determinación (R²): {r2:.4f}\")\n",
    "    \n",
    "    return {'mse': mse, 'rmse': rmse, 'mae': mae, 'r2': r2}\n",
    "\n",
    "# Evaluar en entrenamiento y prueba\n",
    "train_metrics = evaluate_model(y_train, y_pred_train, \"Entrenamiento (XGBoost)\")\n",
    "test_metrics = evaluate_model(y_test, y_pred_test, \"Prueba (XGBoost)\")\n",
    "\n",
    "# Validación cruzada\n",
    "print(f\"\\nValidación cruzada (5-fold):\")\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='r2', n_jobs=-1)\n",
    "print(f\"R² promedio: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "cv_scores_rmse = cross_val_score(pipeline, X_train, y_train, cv=5, \n",
    "                                scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "cv_rmse = np.sqrt(-cv_scores_rmse)\n",
    "print(f\"RMSE promedio: {cv_rmse.mean():,.2f} (+/- {cv_rmse.std() * 2:,.2f})\")\n",
    "\n",
    "# Análisis de Importancia de Características\n",
    "regressor = pipeline.named_steps['regressor']\n",
    "\n",
    "# Obtener la importancia de las características de XGBoost\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': final_features_filtered,\n",
    "    'importance': regressor.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 10 características más importantes (XGBoost):\")\n",
    "print(feature_importance.head(10).to_string(index=False))\n",
    "\n",
    "# Visualizaciones mejoradas\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Predicciones vs Valores Reales (Prueba)\n",
    "axes[0,0].scatter(y_test, y_pred_test, alpha=0.6, color='#00796B', s=30) # Nuevo color\n",
    "axes[0,0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "               color='#FFAB00', linestyle='--', linewidth=2)\n",
    "axes[0,0].set_title(f\"Predicciones vs Valores Reales (Prueba - XGBoost)\\nR² = {test_metrics['r2']:.4f}\", \n",
    "                    fontsize=14, color='#333333')\n",
    "axes[0,0].set_xlabel(\"Valores Reales (precio_mxn)\", fontsize=12)\n",
    "axes[0,0].set_ylabel(\"Predicciones (precio_mxn)\", fontsize=12)\n",
    "axes[0,0].grid(True, alpha=0.3, linestyle=':')\n",
    "\n",
    "# 2. Residuos vs Predicciones\n",
    "residuals_test = y_test - y_pred_test\n",
    "axes[0,1].scatter(y_pred_test, residuals_test, alpha=0.6, color='#5D4037', s=30)\n",
    "axes[0,1].axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[0,1].set_title(\"Residuos vs Predicciones (XGBoost)\", \n",
    "                    fontsize=14, color='#333333')\n",
    "axes[0,1].set_xlabel(\"Predicciones\", fontsize=12)\n",
    "axes[0,1].set_ylabel(\"Residuos (Error)\", fontsize=12)\n",
    "axes[0,1].grid(True, alpha=0.3, linestyle=':')\n",
    "\n",
    "# 3. Distribución de residuos\n",
    "axes[1,0].hist(residuals_test, bins=30, alpha=0.8, color='#1E88E5', edgecolor='black')\n",
    "axes[1,0].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1,0].set_title(\"Distribución de Residuos (XGBoost)\", \n",
    "                    fontsize=14, color='#333333')\n",
    "axes[1,0].set_xlabel(\"Residuos\", fontsize=12)\n",
    "axes[1,0].set_ylabel(\"Frecuencia\", fontsize=12)\n",
    "axes[1,0].grid(True, alpha=0.3, linestyle=':')\n",
    "\n",
    "# 4. Importancia de características (Top 10)\n",
    "top_10_features = feature_importance.head(10)\n",
    "axes[1,1].barh(range(len(top_10_features)), top_10_features['importance'], color='#FF7043')\n",
    "axes[1,1].set_yticks(range(len(top_10_features)))\n",
    "axes[1,1].set_yticklabels(top_10_features['feature'], fontsize=10)\n",
    "axes[1,1].set_title(\"Top 10 Características Más Importantes (XGBoost)\", \n",
    "                    fontsize=14, color='#333333')\n",
    "axes[1,1].set_xlabel(\"Importancia\", fontsize=12)\n",
    "axes[1,1].invert_yaxis() # Pone la más importante arriba\n",
    "axes[1,1].grid(axis='x', alpha=0.3, linestyle=':')\n",
    "\n",
    "plt.suptitle(\"Evaluación del Modelo XGBoost Regressor\", fontsize=16, fontweight='bold')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
    "plt.show()\n",
    "\n",
    "# Comparación Entrenamiento vs Prueba\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Métrica': ['MSE', 'RMSE', 'MAE', 'R²'],\n",
    "    'Entrenamiento': [train_metrics['mse'], train_metrics['rmse'], \n",
    "                     train_metrics['mae'], train_metrics['r2']],\n",
    "    'Prueba': [test_metrics['mse'], test_metrics['rmse'], \n",
    "              test_metrics['mae'], test_metrics['r2']]\n",
    "})\n",
    "\n",
    "print(f\"\\nComparación Entrenamiento vs Prueba:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Detectar posible overfitting\n",
    "r2_diff = train_metrics['r2'] - test_metrics['r2']\n",
    "if r2_diff > 0.05: # Umbral más estricto para XGBoost\n",
    "    print(f\"\\n⚠️  XGBoost detectado con posible sobreajuste (Overfitting):\")\n",
    "    print(f\"   Diferencia R² (Entrenamiento - Prueba): {r2_diff:.4f}\")\n",
    "    print(\"   Considera aumentar el valor de 'reg_alpha' (L1) o 'reg_lambda' (L2), o reducir 'max_depth'.\")\n",
    "elif test_metrics['r2'] < 0.75:\n",
    "    print(f\"\\n⚠️  Modelo con bajo rendimiento para ser XGBoost:\")\n",
    "    print(f\"   R² en prueba: {test_metrics['r2']:.4f}\")\n",
    "else:\n",
    "    print(f\"\\n✅ Modelo XGBoost con muy buen rendimiento y generalización.\")\n",
    "\n",
    "# Guardar el modelo entrenado y métricas (actualizado)\n",
    "model_results_xgb = {\n",
    "    'pipeline': pipeline,\n",
    "    'train_metrics': train_metrics,\n",
    "    'test_metrics': test_metrics,\n",
    "    'feature_importance': feature_importance,\n",
    "    'cv_scores': cv_scores,\n",
    "    'training_time': training_time\n",
    "}\n",
    "\n",
    "print(f\"\\nModelo XGBoost entrenado exitosamente con {len(final_features_filtered)} características\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un diccionario para almacenar los resultados de los modelos\n",
    "model_comparison = {}\n",
    "\n",
    "# Lista de modelos entrenados previamente\n",
    "models = {\n",
    "    \"Linear Regression\": model_results_linear,  # Supongamos que este es el resultado del modelo de regresión lineal\n",
    "    \"Random Forest\": model_results_rf,          # Resultado del modelo Random Forest\n",
    "    \"Gradient Boosting\": model_results_gbm,     # Resultado del modelo Gradient Boosting\n",
    "    \"XGBoost\": model_results_xgb                # Resultado del modelo XGBoost\n",
    "}\n",
    "\n",
    "# Evaluar cada modelo\n",
    "for model_name, model_result in models.items():\n",
    "    pipeline = model_result['pipeline']\n",
    "    test_metrics = model_result['test_metrics']\n",
    "    \n",
    "    # Medir el tiempo de predicción\n",
    "    start_time = time.time()\n",
    "    y_pred_test = pipeline.predict(X_test)\n",
    "    prediction_time = time.time() - start_time\n",
    "    \n",
    "    # Guardar los resultados en el diccionario\n",
    "    model_comparison[model_name] = {\n",
    "        \"R² (Prueba)\": test_metrics['r2'],\n",
    "        \"RMSE (Prueba)\": test_metrics['rmse'],\n",
    "        \"MAE (Prueba)\": test_metrics['mae'],\n",
    "        \"Tiempo de predicción (s)\": prediction_time,\n",
    "        \"Tiempo de entrenamiento (s)\": model_result.get('training_time', 'N/A'),  # Si se almacenó el tiempo de entrenamiento\n",
    "        \"Interpretabilidad\": \"Alta\" if model_name == \"Linear Regression\" else \"Media\" if model_name == \"Random Forest\" else \"Baja\"\n",
    "    }\n",
    "\n",
    "# Crear un DataFrame para visualizar la comparación\n",
    "comparison_df = pd.DataFrame(model_comparison).T\n",
    "\n",
    "# Ordenar por R² en prueba\n",
    "comparison_df = comparison_df.sort_values(by=\"R² (Prueba)\", ascending=False)\n",
    "\n",
    "print(\"Comparación de Modelos:\")\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decidir el modelo final\n",
    "best_model_name = comparison_df.index[0]\n",
    "print(f\"\\nEl modelo seleccionado para producción es: {best_model_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
