{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import pandas as pd\n",
    "import json\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparación de Modelos:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R² (Prueba)</th>\n",
       "      <th>RMSE (Prueba)</th>\n",
       "      <th>MAE (Prueba)</th>\n",
       "      <th>R² (Entrenamiento)</th>\n",
       "      <th>RMSE (Entrenamiento)</th>\n",
       "      <th>MAE (Entrenamiento)</th>\n",
       "      <th>Tiempo de entrenamiento (s)</th>\n",
       "      <th>Tiempo de predicción (s)</th>\n",
       "      <th>Posible Overfitting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest Tuned</th>\n",
       "      <td>0.805242</td>\n",
       "      <td>12799.066542</td>\n",
       "      <td>7239.970685</td>\n",
       "      <td>0.948792</td>\n",
       "      <td>7042.678334</td>\n",
       "      <td>3574.780646</td>\n",
       "      <td>16.268839</td>\n",
       "      <td>0.027672</td>\n",
       "      <td>Sí</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost Tuned</th>\n",
       "      <td>0.804433</td>\n",
       "      <td>12825.61392</td>\n",
       "      <td>7571.263868</td>\n",
       "      <td>0.926414</td>\n",
       "      <td>8442.440016</td>\n",
       "      <td>5520.776718</td>\n",
       "      <td>4.515549</td>\n",
       "      <td>0.003255</td>\n",
       "      <td>Sí</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.797995</td>\n",
       "      <td>13035.013988</td>\n",
       "      <td>7959.820767</td>\n",
       "      <td>0.893429</td>\n",
       "      <td>10159.896145</td>\n",
       "      <td>6591.142756</td>\n",
       "      <td>0.093971</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting Tuned</th>\n",
       "      <td>0.79235</td>\n",
       "      <td>13215.911319</td>\n",
       "      <td>7760.551597</td>\n",
       "      <td>0.931173</td>\n",
       "      <td>8164.858567</td>\n",
       "      <td>5448.204019</td>\n",
       "      <td>14.036204</td>\n",
       "      <td>0.006338</td>\n",
       "      <td>Sí</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.781103</td>\n",
       "      <td>13569.087777</td>\n",
       "      <td>8169.500503</td>\n",
       "      <td>0.907552</td>\n",
       "      <td>9462.805343</td>\n",
       "      <td>6054.633599</td>\n",
       "      <td>0.500972</td>\n",
       "      <td>0.015496</td>\n",
       "      <td>Sí</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.76972</td>\n",
       "      <td>13917.425139</td>\n",
       "      <td>8818.689028</td>\n",
       "      <td>0.825744</td>\n",
       "      <td>12991.65242</td>\n",
       "      <td>8349.936699</td>\n",
       "      <td>1.003435</td>\n",
       "      <td>0.00291</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>0.470845</td>\n",
       "      <td>21097.08459</td>\n",
       "      <td>14326.372073</td>\n",
       "      <td>0.464384</td>\n",
       "      <td>22777.042507</td>\n",
       "      <td>14637.998718</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.00149</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        R² (Prueba) RMSE (Prueba)  MAE (Prueba)  \\\n",
       "Random Forest Tuned        0.805242  12799.066542   7239.970685   \n",
       "XGBoost Tuned              0.804433   12825.61392   7571.263868   \n",
       "XGBoost                    0.797995  13035.013988   7959.820767   \n",
       "Gradient Boosting Tuned     0.79235  13215.911319   7760.551597   \n",
       "Random Forest              0.781103  13569.087777   8169.500503   \n",
       "Gradient Boosting           0.76972  13917.425139   8818.689028   \n",
       "Linear Regression          0.470845   21097.08459  14326.372073   \n",
       "\n",
       "                        R² (Entrenamiento) RMSE (Entrenamiento)  \\\n",
       "Random Forest Tuned               0.948792          7042.678334   \n",
       "XGBoost Tuned                     0.926414          8442.440016   \n",
       "XGBoost                           0.893429         10159.896145   \n",
       "Gradient Boosting Tuned           0.931173          8164.858567   \n",
       "Random Forest                     0.907552          9462.805343   \n",
       "Gradient Boosting                 0.825744          12991.65242   \n",
       "Linear Regression                 0.464384         22777.042507   \n",
       "\n",
       "                        MAE (Entrenamiento) Tiempo de entrenamiento (s)  \\\n",
       "Random Forest Tuned             3574.780646                   16.268839   \n",
       "XGBoost Tuned                   5520.776718                    4.515549   \n",
       "XGBoost                         6591.142756                    0.093971   \n",
       "Gradient Boosting Tuned         5448.204019                   14.036204   \n",
       "Random Forest                   6054.633599                    0.500972   \n",
       "Gradient Boosting               8349.936699                    1.003435   \n",
       "Linear Regression              14637.998718                    0.011445   \n",
       "\n",
       "                        Tiempo de predicción (s) Posible Overfitting  \n",
       "Random Forest Tuned                     0.027672                  Sí  \n",
       "XGBoost Tuned                           0.003255                  Sí  \n",
       "XGBoost                                 0.002206                  No  \n",
       "Gradient Boosting Tuned                 0.006338                  Sí  \n",
       "Random Forest                           0.015496                  Sí  \n",
       "Gradient Boosting                        0.00291                  No  \n",
       "Linear Regression                        0.00149                  No  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparación de Modelos\n",
    "models_dir = '../../models/'\n",
    "model_comparison = {}\n",
    "\n",
    "model_files = {\n",
    "    \"Linear Regression\": \"linear_regression\",\n",
    "    \"Random Forest\": \"random_forest\",\n",
    "    \"Gradient Boosting\": \"gradient_boosting\",\n",
    "    \"XGBoost\": \"xgboost\",\n",
    "    \"Random Forest Tuned\": \"random_forest_tuned\",\n",
    "    \"Gradient Boosting Tuned\": \"gradient_boosting_tuned\",\n",
    "    \"XGBoost Tuned\": \"xgboost_tuned\"\n",
    "}\n",
    "\n",
    "for model_name, file_prefix in model_files.items():\n",
    "    metrics_path = os.path.join(models_dir, f\"{file_prefix}_metrics.json\")\n",
    "    pipeline_path = os.path.join(models_dir, f\"{file_prefix}_pipeline.joblib\")\n",
    "    \n",
    "    if os.path.exists(pipeline_path) and os.path.exists(metrics_path):\n",
    "        with open(metrics_path, 'r') as f:\n",
    "            metrics = json.load(f)\n",
    "        \n",
    "        r2_train = metrics.get('train_metrics', {}).get('r2')\n",
    "        r2_test = metrics.get('test_metrics', {}).get('r2')\n",
    "        \n",
    "        # Heurística para detectar overfitting: diferencia de R² > 0.1\n",
    "        overfitting_flag = (r2_train is not None and r2_test is not None) and (r2_train - r2_test > 0.1)\n",
    "\n",
    "        model_comparison[model_name] = {\n",
    "            \"R² (Prueba)\": r2_test,\n",
    "            \"RMSE (Prueba)\": metrics.get('test_metrics', {}).get('rmse'),\n",
    "            \"MAE (Prueba)\": metrics.get('test_metrics', {}).get('mae'),\n",
    "            \"R² (Entrenamiento)\": r2_train,\n",
    "            \"RMSE (Entrenamiento)\": metrics.get('train_metrics', {}).get('rmse'),\n",
    "            \"MAE (Entrenamiento)\": metrics.get('train_metrics', {}).get('mae'),\n",
    "            \"Tiempo de entrenamiento (s)\": metrics.get('training_time', 'N/A'),\n",
    "            \"Tiempo de predicción (s)\": metrics.get('prediction_time', 'N/A'),\n",
    "            \"Posible Overfitting\": \"Sí\" if overfitting_flag else \"No\"\n",
    "        }\n",
    "\n",
    "# Crear DataFrame para visualización\n",
    "comparison_df = pd.DataFrame(model_comparison).T\n",
    "comparison_df = comparison_df.sort_values(by=\"R² (Prueba)\", ascending=False)\n",
    "\n",
    "print(\"Comparación de Modelos:\")\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "El modelo seleccionado por R² es: Random Forest Tuned\n"
     ]
    }
   ],
   "source": [
    "# Decidir el modelo final\n",
    "best_model_name = comparison_df.index[0]\n",
    "print(f\"\\nEl modelo seleccionado por R² es: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "El modelo seleccionado por tiempo de predicción es: Linear Regression\n"
     ]
    }
   ],
   "source": [
    "best_model_name = comparison_df.sort_values('Tiempo de predicción (s)').index[0]\n",
    "print(f\"\\nEl modelo seleccionado por tiempo de predicción es: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decisión del Modelo Final\n",
    "\n",
    "Ambos modelos con mejor rendimiento, **Random Forest Tuned** y **XGBoost Tuned**, muestran indicios de sobreajuste según nuestra heurística (diferencia entre R² de entrenamiento y prueba > 0.1). \n",
    "\n",
    "Al comparar estos dos modelos:\n",
    "- **Rendimiento (R² de Prueba):** Son prácticamente idénticos (0.805 para RF vs 0.804 para XGB).\n",
    "- **Grado de Sobreajuste:** La diferencia de R² es ligeramente menor en XGBoost Tuned (0.122) que en Random Forest Tuned (0.143).\n",
    "- **Tiempos de Ejecución:** XGBoost Tuned es significativamente más rápido tanto en entrenamiento (4.5s vs 16.3s) como en predicción (0.003s vs 0.028s).\n",
    "\n",
    "El siguiente mejor modelo sin sobreajuste es **XGBoost** (sin tunear), pero su rendimiento es inferior. Dado que **XGBoost Tuned** ofrece un rendimiento casi idéntico al mejor modelo, con un sobreajuste ligeramente menor y tiempos de ejecución muy superiores, se considera la opción más balanceada. Se selecciona **XGBoost Tuned** como el modelo final, asumiendo que el ligero sobreajuste es un compromiso aceptable por el rendimiento y la eficiencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
