{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción por Lotes con Intervalos de Confianza\n",
    "\n",
    "En esta notebook, utilizaremos nuestro modelo XGBoost entrenado para realizar predicciones sobre un conjunto de datos de prueba que no ha visto. Los datos de prueba están particionados por código postal en formato Parquet.\n",
    "\n",
    "El proceso será el siguiente:\n",
    "1. Cargar el modelo entrenado y la lista de características.\n",
    "2. Calcular un intervalo de confianza para las predicciones basándonos en los residuos del conjunto de prueba original.\n",
    "3. Iterar sobre cada partición de datos (por código postal).\n",
    "4. Realizar predicciones para cada lote.\n",
    "5. Añadir la predicción y el intervalo de confianza al DataFrame.\n",
    "6. Guardar los resultados en un nuevo directorio, manteniendo la estructura de particiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo y características cargados.\n"
     ]
    }
   ],
   "source": [
    "# Definir rutas\n",
    "model_path = '../../models/xgboost_tuned_pipeline.joblib'\n",
    "features_path = '../../data/processed/final_features.json'\n",
    "original_data_path = '../../data/processed/final_processed_data.parquet'\n",
    "test_data_dir = '../../data/processed/prod_por_codigo_postal/'\n",
    "output_dir = '../../data/predictions/'\n",
    "\n",
    "# Cargar modelo y características\n",
    "model = joblib.load(model_path)\n",
    "with open(features_path, 'r') as f:\n",
    "    final_features = json.load(f)\n",
    "\n",
    "print(\"Modelo y características cargados.\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "new_final_features = []\n",
    "\n",
    "for feat in final_features:\n",
    "    # 1. Reemplazo para las columnas que deberían llevar el prefijo 'ageb_'\n",
    "    # (Asumiendo que son las que están en MAYÚSCULAS)\n",
    "    if feat.isupper():\n",
    "        new_feature = 'ageb_' + feat\n",
    "    \n",
    "    # 2. Reemplazo de 'num_recamaras' a 'recamaras'\n",
    "    elif feat == 'recamaras':\n",
    "        new_feature = 'num_recamaras'\n",
    "\n",
    "    # 3. Mantener el nombre de la columna si no cumple las condiciones anteriores\n",
    "    else:\n",
    "        new_feature = feat\n",
    "    \n",
    "    new_final_features.append(new_feature)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "new_final_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calcular Límites para el Intervalo de Confianza usando Error Relativo Porcentual\n",
    "\n",
    "Para que el intervalo de confianza sea más intuitivo y se adapte a la escala del precio, usaremos una variación porcentual en lugar de un monto absoluto. Un error de $10,000 es significativo para una propiedad barata, pero menor para una cara. El error porcentual captura esto.\n",
    "\n",
    "El proceso es el siguiente:\n",
    "1. Usar un conjunto de validación para el cual conocemos el precio real.\n",
    "2. Realizar predicciones sobre este conjunto.\n",
    "3. Calcular el **error relativo**: `(precio_real - predicción) / predicción`.\n",
    "4. Crear contenedores de precios basados en las predicciones y, para cada uno, calcular los percentiles 5 y 95 del error relativo. Estos serán nuestros factores de ajuste (ej. -0.15 y +0.10).\n",
    "5. Al predecir en nuevos datos, aplicaremos estos factores para definir el intervalo: `limite = prediccion * (1 + factor_error)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factores de error relativo calculados a partir del set de validación.\n"
     ]
    }
   ],
   "source": [
    "# Cargar los datos originales para crear un set de validación\n",
    "original_df = pd.read_parquet(original_data_path)\n",
    "\n",
    "# Dividir los datos para obtener un conjunto de validación (estratificado si es posible)\n",
    "# Usamos el mismo random_state para asegurar la reproducibilidad\n",
    "_, df_val = train_test_split(original_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- 1. Caracterización del Error Relativo en el Set de Validación ---\n",
    "\n",
    "# Realizar predicciones en el set de validación\n",
    "val_predictions = model.predict(df_val[final_features])\n",
    "\n",
    "# Calcular error relativo: (real - pred) / pred\n",
    "# Se añade un valor pequeño (epsilon) para evitar división por cero\n",
    "epsilon = 1e-6\n",
    "relative_errors = (df_val['precio_mxn'] - val_predictions) / (val_predictions + epsilon)\n",
    "\n",
    "# Crear contenedores basados en las predicciones\n",
    "prediction_bins = pd.qcut(val_predictions, q=10, labels=False, duplicates='drop')\n",
    "\n",
    "# Calcular límites de error relativo por contenedor\n",
    "error_factors = {}\n",
    "for bin_label in np.unique(prediction_bins):\n",
    "    bin_rel_errors = relative_errors[prediction_bins == bin_label]\n",
    "    lower_factor = bin_rel_errors.quantile(0.05)\n",
    "    upper_factor = bin_rel_errors.quantile(0.95)\n",
    "    error_factors[bin_label] = (lower_factor, upper_factor)\n",
    "\n",
    "# Necesitamos los umbrales de los contenedores para clasificar nuevas predicciones\n",
    "_, bin_thresholds = pd.qcut(val_predictions, q=10, retbins=True, duplicates='drop')\n",
    "bin_thresholds[0] = -np.inf # El primer límite es -infinito\n",
    "bin_thresholds[-1] = np.inf # El último límite es +infinito\n",
    "\n",
    "print(\"Factores de error relativo calculados a partir del set de validación.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (-0.5212149206533959, 0.7888172347117516),\n",
       " 1: (-0.4694246513319183, 0.3872370661461857),\n",
       " 2: (-0.3954911148858698, 0.4728319576045606),\n",
       " 3: (-0.36359399879314225, 0.3557330582987902),\n",
       " 4: (-0.36880268250821374, 0.4536850272730025),\n",
       " 5: (-0.3209423313164633, 0.4010791935617052),\n",
       " 6: (-0.3902653771326588, 0.4635978000503158),\n",
       " 7: (-0.37005361345313287, 0.32664181599986475),\n",
       " 8: (-0.42097986999172965, 0.35635344015893855),\n",
       " 9: (-0.4628565347920143, 0.41068234913731505)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicciones por lotes con intervalos de confianza generadas.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 2. Inferencia por Lotes aplicando los límites de error ---\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterar sobre cada archivo de testeo particionado\n",
    "for filename in os.listdir(test_data_dir):\n",
    "    if filename.endswith('.parquet'):\n",
    "        partition_path = os.path.join(test_data_dir, filename)\n",
    "        df_partition = pd.read_parquet(partition_path)\n",
    "        \n",
    "        if df_partition.empty:\n",
    "            continue\n",
    "        \n",
    "        #df_partition['es_penthouse'] = 0\n",
    "        #rename_map = dict(zip(new_final_features, final_features))\n",
    "        # Aplica el renombramiento al DataFrame\n",
    "        #df_partition.rename(columns=rename_map, inplace=True)\n",
    "        #df_partition[final_features] = df_partition[final_features].replace('*',0)\n",
    "        #df_partition[final_features] = df_partition[final_features].astype(float)\n",
    "\n",
    "        # Realizar predicciones sobre el lote\n",
    "        predictions = model.predict(df_partition[final_features])\n",
    "        # Asegurar que las predicciones no sean negativas\n",
    "        predictions[predictions < 0] = None\n",
    "        df_partition['prediction'] = predictions\n",
    "        \n",
    "        # Asignar cada predicción a un bin usando los umbrales calculados\n",
    "        df_partition['prediction_bin'] = pd.cut(df_partition['prediction'], bins=bin_thresholds, labels=False, right=False)\n",
    "        \n",
    "        # Aplicar factores de error relativo\n",
    "        df_partition['lower_bound'] = df_partition.apply(lambda row: row['prediction'] * (1 + error_factors.get(row['prediction_bin'], (0,0))[0]), axis=1)\n",
    "        df_partition['upper_bound'] = df_partition.apply(lambda row: row['prediction'] * (1 + error_factors.get(row['prediction_bin'], (0,0))[1]), axis=1)\n",
    "        \n",
    "        # Asegurar que los límites del intervalo no sean negativos\n",
    "        df_partition['lower_bound'] = df_partition['lower_bound'].clip(lower=0)\n",
    "        df_partition['upper_bound'] = df_partition['upper_bound'].clip(lower=0)\n",
    "        \n",
    "        # Guardar resultados\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "        df_partition.to_parquet(output_path)\n",
    "\n",
    "print(\"\\nPredicciones por lotes con intervalos de confianza generadas.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
